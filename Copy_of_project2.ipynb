{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of project2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pengyk/COMP551/blob/main/Copy_of_project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpnx1NpKwdSA"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.core.debugger import set_trace\n",
        "import warnings\n",
        "from random import shuffle, randrange\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZ3yFgk59uB"
      },
      "source": [
        "digits = load_digits()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcFJF8XrqKhz"
      },
      "source": [
        "def ontHotEncoder(Y):\n",
        "    output = pd.get_dummies(Y)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdYR2YysyOu-"
      },
      "source": [
        "def cost_fn(x, y, w):\n",
        "    N, D = x.shape                                                       \n",
        "    yhat = np.dot(x, w)\n",
        "    J = - np.sum(y * np.log(yhat+1e-6))  #log1p calculates log(1+x) to remove floating point inaccuracies \n",
        "    return J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNFh8PD9wtNR"
      },
      "source": [
        "def softmax(z):\n",
        "    exps = np.exp(z - np.max(z))\n",
        "    return exps / np.sum(exps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6zitFnw4dXi"
      },
      "source": [
        "def delta_cross_entropy(X,y):\n",
        "    \"\"\"\n",
        "    X is the output from fully connected layer (num_examples x num_classes)\n",
        "    y is labels (num_examples x 1)\n",
        "    \tNote that y is not one-hot encoded vector. \n",
        "    \tIt can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    print(\"delta_cross_entropy: X is here!\")\n",
        "    print(X)\n",
        "\n",
        "    print(X.shape)\n",
        "    grad = softmax(X)\n",
        "    print(grad)\n",
        "    print(grad.shape)\n",
        "    grad[range(m),y] -= 1\n",
        "    grad = grad/m\n",
        "    return grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXgMl8UCYhdK"
      },
      "source": [
        "def gradient(x, y,w):\n",
        "    print(\"gardient, X is here\")\n",
        "    print(x)\n",
        "    yh = softmax(np.dot(x, w))    # predictions  size N\n",
        "    # J = - np.sum(y * np.log(yhat+1e-6))\n",
        "    y_afterOneHot = ontHotEncoder(yh)\n",
        "\n",
        "    grad = delta_cross_entropy(y_afterOneHot,y)/N        # divide by N because cost is mean over N points\n",
        "    return grad                         # size D                      # size D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU1jD5EO48qp"
      },
      "source": [
        "class MultiClassLogisticRegression:\n",
        "    \n",
        "    def __init__(self, add_bias=True, learning_rate=.1, epsilon=1e-4, max_iters=1e5, verbose=False):\n",
        "        self.add_bias = add_bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epsilon = epsilon                        #to get the tolerance for the norm of gradients \n",
        "        self.max_iters = max_iters                    #maximum number of iteration of gradient descent\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def fit(self, x, y, optimizer):\n",
        "        if x.ndim == 1:\n",
        "            x = x[:, None]\n",
        "        if self.add_bias:\n",
        "            N = x.shape[0]\n",
        "            x = np.column_stack([x,np.ones(N)])\n",
        "        N,D = x.shape\n",
        "        w0 = np.zeros(D)                                # initialize the weights to 0\n",
        "        self.w = optimizer.run(gradient, x, y, w0)      # run the optimizer to get the optimal weights\n",
        "        return self\n",
        "    \n",
        "    def predict(self, x):\n",
        "        if x.ndim == 1:\n",
        "            x = x[:, None]\n",
        "        Nt = x.shape[0]\n",
        "        if self.add_bias:\n",
        "            x = np.column_stack([x,np.ones(Nt)])\n",
        "        yh = softmax(np.dot(x,self.w))\n",
        "        return yh\n",
        "\n",
        "MultiClassLogisticRegression.gradient = gradient    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLMpddxbHeSL"
      },
      "source": [
        "class GradientDescent:\n",
        "   def __init__(self, learning_rate=.001, max_iters=1e4, epsilon=1e-8, record_history=False, batch_size = 20, momentum = 0.9):\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iters = max_iters\n",
        "        self.record_history = record_history\n",
        "        self.epsilon = epsilon\n",
        "        if record_history:\n",
        "            self.w_history = []                 #to store the weight history for visualization\n",
        "            \n",
        "   def run(self, gradient_fn, x, y, w):\n",
        "      grad = np.inf\n",
        "      t = 1\n",
        "      while np.linalg.norm(grad) > self.epsilon and t < self.max_iters:\n",
        "          mini_X = []\n",
        "          mini_Y = []\n",
        "          for i in range (0, self.batch_size):\n",
        "            rand_index = randrange(0, x.shape[0]-1)\n",
        "            if len(mini_X) == 0:\n",
        "              mini_X = x[rand_index]\n",
        "            else:\n",
        "              mini_X = np.vstack((mini_X,x[rand_index])) \n",
        "            mini_Y.append(y[rand_index])\n",
        "          print(mini_X.shape)\n",
        "          print(len(mini_Y))\n",
        "          print(mini_X)\n",
        "          print(mini_Y)\n",
        "          grad = gradient_fn(mini_X,mini_Y,w)  #compute gradient with present weight\n",
        "          print(np.linalg.norm(grad))\n",
        "          print()\n",
        "          w = w - np.dot(self.learning_rate, grad)  #weigh update\n",
        "          if self.record_history:\n",
        "            self.w_history.append(w)\n",
        "          t+=1\n",
        "      return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8PUYJQDLATc"
      },
      "source": [
        "Digits dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jlmgav4K_1D",
        "outputId": "8f3d8d62-954e-43fa-a1ce-980fb94e71f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "digits = load_digits()\n",
        "\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[1]) \n",
        "plt.show() \n",
        "x, y = digits['data'], digits['target']\n",
        "# print(x[0].shape)\n",
        "# print(np.unique(y))\n",
        "# print(y)\n",
        "# print(y.shape)\n",
        "# print(x[0].shape)\n",
        "# print(x[0])\n",
        "# print(x.type)\n",
        "x = [ele[:-1] for ele in x]\n",
        "x = np.asarray(x) \n",
        "# y_oneHot = ontHotEncoder(y)\n",
        "# print(y_oneHot)\n",
        "# print(y_oneHot.shape)\n",
        "\n",
        "model = MultiClassLogisticRegression()\n",
        "optimizer = GradientDescent()\n",
        "model.fit(x,y, optimizer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(20, 64)\n",
            "20\n",
            "[[ 0.  0.  1. ... 16. 11.  1.]\n",
            " [ 0.  0.  9. ...  2.  0.  1.]\n",
            " [ 0.  1. 15. ...  0.  0.  1.]\n",
            " ...\n",
            " [ 0.  2. 11. ...  0.  0.  1.]\n",
            " [ 0.  1.  7. ...  7.  0.  1.]\n",
            " [ 0.  0.  5. ... 16. 14.  1.]]\n",
            "[6, 5, 5, 1, 2, 8, 2, 3, 6, 9, 6, 3, 6, 7, 4, 8, 4, 3, 3, 2]\n",
            "gardient, X is here\n",
            "[[ 0.  0.  1. ... 16. 11.  1.]\n",
            " [ 0.  0.  9. ...  2.  0.  1.]\n",
            " [ 0.  1. 15. ...  0.  0.  1.]\n",
            " ...\n",
            " [ 0.  2. 11. ...  0.  0.  1.]\n",
            " [ 0.  1.  7. ...  7.  0.  1.]\n",
            " [ 0.  0.  5. ... 16. 14.  1.]]\n",
            "delta_cross_entropy: X is here!\n",
            "    0.05\n",
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "5      1\n",
            "6      1\n",
            "7      1\n",
            "8      1\n",
            "9      1\n",
            "10     1\n",
            "11     1\n",
            "12     1\n",
            "13     1\n",
            "14     1\n",
            "15     1\n",
            "16     1\n",
            "17     1\n",
            "18     1\n",
            "19     1\n",
            "(20, 1)\n",
            "        0.05\n",
            "0   0.049988\n",
            "1   0.049988\n",
            "2   0.049988\n",
            "3   0.049988\n",
            "4   0.049988\n",
            "5   0.049988\n",
            "6   0.049988\n",
            "7   0.049988\n",
            "8   0.049988\n",
            "9   0.049988\n",
            "10  0.049988\n",
            "11  0.049988\n",
            "12  0.049988\n",
            "13  0.049988\n",
            "14  0.049988\n",
            "15  0.049988\n",
            "16  0.049988\n",
            "17  0.049988\n",
            "18  0.049988\n",
            "19  0.049988\n",
            "(20, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-196-2fa8f84ddefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiClassLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-194-d623f2e5a08f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# initialize the weights to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# run the optimizer to get the optimal weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-195-8cf1834edb63>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, gradient_fn, x, y, w)\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m           \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#compute gradient with present weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-193-b0c614689df5>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(x, y, w)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_afterOneHot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0montHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_afterOneHot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m        \u001b[0;31m# divide by N because cost is mean over N points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m                         \u001b[0;31m# size D                      # size D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-192-86591d912501>\u001b[0m in \u001b[0;36mdelta_cross_entropy\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnan_idxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2893\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(range(0, 20), [6, 5, 5, 1, 2, 8, 2, 3, 6, 9, 6, 3, 6, 7, 4, 8, 4, 3, 3, 2])' is an invalid key"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLFjamlp1r9D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}